{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Algorithms in the MapReduce Framework\n",
    "\n",
    "\n",
    "In this assignment, you will be implementing some of the MapReduce algorithms we saw during class. The goal of this assignment is to help you gain some experience in \"thinking in MapReduce\" terms. To this end, we will be using small datasets that you can inspect to determine the correctness of your results. \n",
    "\n",
    "Before you start this assignment you need to review the slides from the MapReduce lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Python Version of MapReduce\n",
    "\n",
    "In the directory of this assignment you will find a python library called `MapReduce.py`. This is a toy-example implementation of the MapReduce programming model that we will be using for the purposes of this assignment. The framework implements the MapReduce programming model but it executes everything on a single machine---it does not use any parallel computation. The format of the input files for this version of MapReduce is `.json`.\n",
    " \n",
    "Bellow you can find the word count example we discussed in class, implemented as a MapReduce program using the provided framework. The input documents correspond to books. The input file for our word count program corresponds to the `books.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[\", 11]\n",
      "[\"Paradise\", 1]\n",
      "[\"Lost\", 1]\n",
      "[\"by\", 12]\n",
      "[\"John\", 1]\n",
      "[\"Milton\", 1]\n",
      "[\"1667\", 1]\n",
      "[\"]\", 11]\n",
      "[\"Book\", 2]\n",
      "[\"I\", 25]\n",
      "[\"Of\", 4]\n",
      "[\"Man\", 3]\n",
      "[\"'\", 12]\n",
      "[\"s\", 7]\n",
      "[\"first\", 4]\n",
      "[\"disobedience\", 1]\n",
      "[\",\", 101]\n",
      "[\"and\", 38]\n",
      "[\"the\", 58]\n",
      "[\"fruit\", 1]\n",
      "[\"that\", 13]\n",
      "[\"forbidden\", 1]\n",
      "[\"tree\", 1]\n",
      "[\"whose\", 1]\n",
      "[\"mortal\", 1]\n",
      "[\"taste\", 1]\n",
      "[\"Brought\", 1]\n",
      "[\"death\", 2]\n",
      "[\"into\", 1]\n",
      "[\"World\", 1]\n",
      "[\"all\", 4]\n",
      "[\"our\", 2]\n",
      "[\"woe\", 1]\n",
      "[\"With\", 1]\n",
      "[\"loss\", 1]\n",
      "[\"of\", 35]\n",
      "[\"Eden\", 1]\n",
      "[\"till\", 1]\n",
      "[\"one\", 3]\n",
      "[\"greater\", 1]\n",
      "[\"Restore\", 1]\n",
      "[\"us\", 3]\n",
      "[\"regain\", 1]\n",
      "[\"blissful\", 1]\n",
      "[\"seat\", 1]\n",
      "[\"Sing\", 3]\n",
      "[\"Heavenly\", 1]\n",
      "[\"Muse\", 1]\n",
      "[\"on\", 4]\n",
      "[\"secret\", 1]\n",
      "[\"top\", 1]\n",
      "[\"Oreb\", 1]\n",
      "[\"or\", 4]\n",
      "[\"Sinai\", 1]\n",
      "[\"didst\", 1]\n",
      "[\"inspire\", 1]\n",
      "[\"That\", 4]\n",
      "[\"shepherd\", 1]\n",
      "[\"who\", 2]\n",
      "[\"taught\", 1]\n",
      "[\"chosen\", 1]\n",
      "[\"seed\", 1]\n",
      "[\"In\", 3]\n",
      "[\"beginning\", 2]\n",
      "[\"how\", 1]\n",
      "[\"heavens\", 1]\n",
      "[\"earth\", 4]\n",
      "[\"Rose\", 1]\n",
      "[\"out\", 1]\n",
      "[\"Chaos\", 1]\n",
      "[\":\", 14]\n",
      "[\"if\", 1]\n",
      "[\"Sion\", 1]\n",
      "[\"hill\", 1]\n",
      "[\"Delight\", 1]\n",
      "[\"thee\", 2]\n",
      "[\"more\", 2]\n",
      "[\"Siloa\", 1]\n",
      "[\"brook\", 1]\n",
      "[\"flowed\", 1]\n",
      "[\"Fast\", 1]\n",
      "[\"oracle\", 1]\n",
      "[\"God\", 7]\n",
      "[\"thence\", 1]\n",
      "[\"Invoke\", 1]\n",
      "[\"thy\", 7]\n",
      "[\"aid\", 1]\n",
      "[\"to\", 20]\n",
      "[\"my\", 6]\n",
      "[\"adventurous\", 1]\n",
      "[\"song\", 3]\n",
      "[\"with\", 10]\n",
      "[\"no\", 2]\n",
      "[\"middle\", 1]\n",
      "[\"flight\", 1]\n",
      "[\"intends\", 1]\n",
      "[\"soar\", 1]\n",
      "[\"Above\", 1]\n",
      "[\"th\", 1]\n",
      "[\"Aonian\", 1]\n",
      "[\"mount\", 1]\n",
      "[\"while\", 1]\n",
      "[\"it\", 10]\n",
      "[\"pursues\", 1]\n",
      "[\"Things\", 1]\n",
      "[\"unattempted\", 1]\n",
      "[\"yet\", 2]\n",
      "[\"in\", 14]\n",
      "[\"prose\", 1]\n",
      "[\"rhyme\", 1]\n",
      "[\".\", 46]\n",
      "[\"The\", 13]\n",
      "[\"Parent\", 1]\n",
      "[\"Assistant\", 1]\n",
      "[\"Maria\", 1]\n",
      "[\"Edgeworth\", 1]\n",
      "[\"THE\", 3]\n",
      "[\"ORPHANS\", 1]\n",
      "[\"Near\", 1]\n",
      "[\"ruins\", 1]\n",
      "[\"castle\", 1]\n",
      "[\"Rossmore\", 1]\n",
      "[\"Ireland\", 1]\n",
      "[\"is\", 3]\n",
      "[\"a\", 29]\n",
      "[\"small\", 1]\n",
      "[\"cabin\", 1]\n",
      "[\"which\", 2]\n",
      "[\"there\", 3]\n",
      "[\"once\", 1]\n",
      "[\"lived\", 2]\n",
      "[\"widow\", 1]\n",
      "[\"her\", 8]\n",
      "[\"four\", 1]\n",
      "[\"children\", 1]\n",
      "[\"As\", 1]\n",
      "[\"long\", 4]\n",
      "[\"as\", 7]\n",
      "[\"she\", 5]\n",
      "[\"was\", 16]\n",
      "[\"able\", 1]\n",
      "[\"work\", 1]\n",
      "[\"very\", 4]\n",
      "[\"industrious\", 1]\n",
      "[\"accounted\", 1]\n",
      "[\"best\", 3]\n",
      "[\"spinner\", 1]\n",
      "[\"parish\", 1]\n",
      "[\";\", 14]\n",
      "[\"but\", 3]\n",
      "[\"overworked\", 1]\n",
      "[\"herself\", 1]\n",
      "[\"at\", 1]\n",
      "[\"last\", 1]\n",
      "[\"fell\", 1]\n",
      "[\"ill\", 1]\n",
      "[\"so\", 1]\n",
      "[\"could\", 1]\n",
      "[\"not\", 3]\n",
      "[\"sit\", 2]\n",
      "[\"wheel\", 1]\n",
      "[\"used\", 1]\n",
      "[\"do\", 1]\n",
      "[\"obliged\", 1]\n",
      "[\"give\", 1]\n",
      "[\"up\", 1]\n",
      "[\"eldest\", 1]\n",
      "[\"daughter\", 1]\n",
      "[\"Mary\", 1]\n",
      "[\"Emma\", 2]\n",
      "[\"Jane\", 1]\n",
      "[\"Austen\", 1]\n",
      "[\"1816\", 1]\n",
      "[\"VOLUME\", 1]\n",
      "[\"CHAPTER\", 1]\n",
      "[\"Woodhouse\", 1]\n",
      "[\"handsome\", 1]\n",
      "[\"clever\", 1]\n",
      "[\"rich\", 1]\n",
      "[\"comfortable\", 1]\n",
      "[\"home\", 3]\n",
      "[\"happy\", 4]\n",
      "[\"disposition\", 1]\n",
      "[\"seemed\", 2]\n",
      "[\"unite\", 1]\n",
      "[\"some\", 2]\n",
      "[\"blessings\", 1]\n",
      "[\"existence\", 1]\n",
      "[\"had\", 9]\n",
      "[\"nearly\", 2]\n",
      "[\"twenty\", 1]\n",
      "[\"-\", 4]\n",
      "[\"years\", 1]\n",
      "[\"world\", 4]\n",
      "[\"little\", 2]\n",
      "[\"distress\", 1]\n",
      "[\"vex\", 1]\n",
      "[\"She\", 1]\n",
      "[\"youngest\", 1]\n",
      "[\"two\", 2]\n",
      "[\"daughters\", 1]\n",
      "[\"most\", 1]\n",
      "[\"affectionate\", 1]\n",
      "[\"indulgent\", 1]\n",
      "[\"father\", 1]\n",
      "[\"consequence\", 1]\n",
      "[\"sister\", 1]\n",
      "[\"marriage\", 1]\n",
      "[\"been\", 2]\n",
      "[\"mistress\", 1]\n",
      "[\"his\", 4]\n",
      "[\"house\", 1]\n",
      "[\"from\", 3]\n",
      "[\"early\", 1]\n",
      "[\"period\", 1]\n",
      "[\"Her\", 1]\n",
      "[\"mother\", 2]\n",
      "[\"died\", 1]\n",
      "[\"too\", 1]\n",
      "[\"ago\", 1]\n",
      "[\"for\", 5]\n",
      "[\"have\", 1]\n",
      "[\"than\", 1]\n",
      "[\"an\", 2]\n",
      "[\"indistinct\", 1]\n",
      "[\"remembrance\", 1]\n",
      "[\"caresses\", 1]\n",
      "[\"place\", 1]\n",
      "[\"supplied\", 1]\n",
      "[\"excellent\", 1]\n",
      "[\"woman\", 1]\n",
      "[\"governess\", 1]\n",
      "[\"fallen\", 1]\n",
      "[\"short\", 1]\n",
      "[\"affection\", 1]\n",
      "[\"Ball\", 1]\n",
      "[\"Cross\", 1]\n",
      "[\"G\", 2]\n",
      "[\"K\", 2]\n",
      "[\"Chesterton\", 2]\n",
      "[\"1909\", 1]\n",
      "[\"A\", 3]\n",
      "[\"DISCUSSION\", 1]\n",
      "[\"SOMEWHAT\", 1]\n",
      "[\"IN\", 1]\n",
      "[\"AIR\", 1]\n",
      "[\"flying\", 2]\n",
      "[\"ship\", 1]\n",
      "[\"Professor\", 1]\n",
      "[\"Lucifer\", 1]\n",
      "[\"sang\", 2]\n",
      "[\"through\", 1]\n",
      "[\"skies\", 1]\n",
      "[\"like\", 1]\n",
      "[\"silver\", 1]\n",
      "[\"arrow\", 1]\n",
      "[\"bleak\", 2]\n",
      "[\"white\", 3]\n",
      "[\"steel\", 1]\n",
      "[\"gleaming\", 1]\n",
      "[\"blue\", 1]\n",
      "[\"emptiness\", 1]\n",
      "[\"evening\", 2]\n",
      "[\"far\", 2]\n",
      "[\"above\", 2]\n",
      "[\"expression\", 1]\n",
      "[\"men\", 2]\n",
      "[\"be\", 2]\n",
      "[\"stars\", 1]\n",
      "[\"professor\", 1]\n",
      "[\"himself\", 1]\n",
      "[\"invented\", 2]\n",
      "[\"machine\", 1]\n",
      "[\"also\", 1]\n",
      "[\"everything\", 1]\n",
      "[\"King\", 2]\n",
      "[\"James\", 2]\n",
      "[\"Bible\", 2]\n",
      "[\"Old\", 1]\n",
      "[\"Testament\", 1]\n",
      "[\"First\", 1]\n",
      "[\"Moses\", 1]\n",
      "[\"Called\", 1]\n",
      "[\"Genesis\", 1]\n",
      "[\"1\", 6]\n",
      "[\"created\", 1]\n",
      "[\"heaven\", 1]\n",
      "[\"2\", 1]\n",
      "[\"And\", 11]\n",
      "[\"without\", 2]\n",
      "[\"form\", 1]\n",
      "[\"void\", 1]\n",
      "[\"darkness\", 3]\n",
      "[\"upon\", 3]\n",
      "[\"face\", 2]\n",
      "[\"deep\", 1]\n",
      "[\"Spirit\", 1]\n",
      "[\"moved\", 1]\n",
      "[\"waters\", 1]\n",
      "[\"3\", 1]\n",
      "[\"said\", 3]\n",
      "[\"Let\", 1]\n",
      "[\"light\", 5]\n",
      "[\"4\", 1]\n",
      "[\"saw\", 2]\n",
      "[\"good\", 1]\n",
      "[\"divided\", 1]\n",
      "[\"5\", 1]\n",
      "[\"called\", 2]\n",
      "[\"Day\", 1]\n",
      "[\"he\", 5]\n",
      "[\"Night\", 1]\n",
      "[\"morning\", 1]\n",
      "[\"were\", 4]\n",
      "[\"day\", 2]\n",
      "[\"Who\", 1]\n",
      "[\"Was\", 1]\n",
      "[\"Thursday\", 1]\n",
      "[\"1908\", 1]\n",
      "[\"To\", 1]\n",
      "[\"Edmund\", 1]\n",
      "[\"Clerihew\", 1]\n",
      "[\"Bentley\", 1]\n",
      "[\"cloud\", 3]\n",
      "[\"mind\", 1]\n",
      "[\"wailing\", 1]\n",
      "[\"went\", 1]\n",
      "[\"weather\", 1]\n",
      "[\"Yea\", 1]\n",
      "[\"sick\", 1]\n",
      "[\"soul\", 2]\n",
      "[\"when\", 2]\n",
      "[\"we\", 2]\n",
      "[\"boys\", 1]\n",
      "[\"together\", 1]\n",
      "[\"Science\", 1]\n",
      "[\"announced\", 1]\n",
      "[\"nonentity\", 1]\n",
      "[\"art\", 3]\n",
      "[\"admired\", 1]\n",
      "[\"decay\", 1]\n",
      "[\"old\", 4]\n",
      "[\"ended\", 1]\n",
      "[\"you\", 8]\n",
      "[\"gay\", 2]\n",
      "[\"Round\", 1]\n",
      "[\"antic\", 1]\n",
      "[\"order\", 1]\n",
      "[\"their\", 2]\n",
      "[\"crippled\", 1]\n",
      "[\"vices\", 1]\n",
      "[\"came\", 1]\n",
      "[\"--\", 3]\n",
      "[\"Lust\", 1]\n",
      "[\"lost\", 2]\n",
      "[\"its\", 2]\n",
      "[\"laughter\", 1]\n",
      "[\"fear\", 1]\n",
      "[\"shame\", 1]\n",
      "[\"Like\", 1]\n",
      "[\"lock\", 1]\n",
      "[\"Whistler\", 1]\n",
      "[\"lit\", 1]\n",
      "[\"aimless\", 1]\n",
      "[\"gloom\", 1]\n",
      "[\"Men\", 1]\n",
      "[\"showed\", 1]\n",
      "[\"own\", 1]\n",
      "[\"feather\", 1]\n",
      "[\"proudly\", 1]\n",
      "[\"plume\", 1]\n",
      "[\"Life\", 1]\n",
      "[\"fly\", 1]\n",
      "[\"faded\", 1]\n",
      "[\"drone\", 1]\n",
      "[\"stung\", 1]\n",
      "[\"indeed\", 2]\n",
      "[\"young\", 1]\n",
      "[\"Poems\", 1]\n",
      "[\"William\", 2]\n",
      "[\"Blake\", 1]\n",
      "[\"1789\", 1]\n",
      "[\"SONGS\", 2]\n",
      "[\"OF\", 3]\n",
      "[\"INNOCENCE\", 2]\n",
      "[\"AND\", 1]\n",
      "[\"EXPERIENCE\", 1]\n",
      "[\"BOOK\", 2]\n",
      "[\"THEL\", 1]\n",
      "[\"INTRODUCTION\", 1]\n",
      "[\"Piping\", 2]\n",
      "[\"down\", 2]\n",
      "[\"valleys\", 1]\n",
      "[\"wild\", 1]\n",
      "[\"songs\", 3]\n",
      "[\"pleasant\", 1]\n",
      "[\"glee\", 1]\n",
      "[\"On\", 1]\n",
      "[\"child\", 2]\n",
      "[\"laughing\", 1]\n",
      "[\"me\", 2]\n",
      "[\"\\\"\", 4]\n",
      "[\"Pipe\", 1]\n",
      "[\"about\", 1]\n",
      "[\"Lamb\", 1]\n",
      "[\"!\\\"\", 1]\n",
      "[\"So\", 4]\n",
      "[\"piped\", 2]\n",
      "[\"merry\", 1]\n",
      "[\"cheer\", 2]\n",
      "[\"Piper\", 2]\n",
      "[\"pipe\", 3]\n",
      "[\"again\", 2]\n",
      "[\";\\\"\", 1]\n",
      "[\"wept\", 2]\n",
      "[\"hear\", 3]\n",
      "[\"Drop\", 1]\n",
      "[\":!\\\"\", 1]\n",
      "[\"same\", 1]\n",
      "[\"While\", 1]\n",
      "[\"joy\", 2]\n",
      "[\"write\", 2]\n",
      "[\"book\", 1]\n",
      "[\"may\", 4]\n",
      "[\"read\", 1]\n",
      "[\".\\\"\", 1]\n",
      "[\"vanish\", 1]\n",
      "[\"d\", 4]\n",
      "[\"sight\", 1]\n",
      "[\"pluck\", 1]\n",
      "[\"hollow\", 1]\n",
      "[\"reed\", 1]\n",
      "[\"made\", 1]\n",
      "[\"rural\", 1]\n",
      "[\"pen\", 1]\n",
      "[\"stain\", 1]\n",
      "[\"water\", 1]\n",
      "[\"clear\", 1]\n",
      "[\"wrote\", 1]\n",
      "[\"Every\", 1]\n",
      "[\"Tragedie\", 1]\n",
      "[\"Julius\", 1]\n",
      "[\"Caesar\", 1]\n",
      "[\"Shakespeare\", 1]\n",
      "[\"1599\", 1]\n",
      "[\"Actus\", 1]\n",
      "[\"Primus\", 1]\n",
      "[\"Scoena\", 1]\n",
      "[\"Prima\", 1]\n",
      "[\"Enter\", 1]\n",
      "[\"Flauius\", 2]\n",
      "[\"Murellus\", 1]\n",
      "[\"certaine\", 1]\n",
      "[\"Commoners\", 1]\n",
      "[\"ouer\", 1]\n",
      "[\"Stage\", 1]\n",
      "[\"Hence\", 1]\n",
      "[\"idle\", 1]\n",
      "[\"Creatures\", 1]\n",
      "[\"get\", 1]\n",
      "[\"Is\", 1]\n",
      "[\"this\", 1]\n",
      "[\"Holiday\", 1]\n",
      "[\"?\", 7]\n",
      "[\"What\", 2]\n",
      "[\"know\", 1]\n",
      "[\"(\", 4]\n",
      "[\"Being\", 1]\n",
      "[\"Mechanicall\", 1]\n",
      "[\")\", 2]\n",
      "[\"ought\", 1]\n",
      "[\"walke\", 1]\n",
      "[\"Vpon\", 1]\n",
      "[\"labouring\", 1]\n",
      "[\"signe\", 1]\n",
      "[\"your\", 1]\n",
      "[\"Profession\", 1]\n",
      "[\"Speake\", 1]\n",
      "[\"what\", 3]\n",
      "[\"Trade\", 4]\n",
      "[\"thou\", 3]\n",
      "[\"Car\", 1]\n",
      "[\"Why\", 1]\n",
      "[\"Sir\", 4]\n",
      "[\"Carpenter\", 1]\n",
      "[\"Mur\", 2]\n",
      "[\"Where\", 1]\n",
      "[\"Leather\", 1]\n",
      "[\"Apron\", 1]\n",
      "[\"Rule\", 1]\n",
      "[\"dost\", 1]\n",
      "[\"Apparrell\", 1]\n",
      "[\"You\", 1]\n",
      "[\"sir\", 1]\n",
      "[\"are\", 2]\n",
      "[\"Cobl\", 1]\n",
      "[\"Truely\", 1]\n",
      "[\"respect\", 1]\n",
      "[\"fine\", 1]\n",
      "[\"Workman\", 1]\n",
      "[\"am\", 1]\n",
      "[\"would\", 1]\n",
      "[\"say\", 1]\n",
      "[\"Cobler\", 1]\n",
      "[\"But\", 1]\n",
      "[\"Answer\", 1]\n",
      "[\"directly\", 1]\n",
      "[\"Cob\", 1]\n",
      "[\"hope\", 1]\n",
      "[\"vse\", 1]\n",
      "[\"safe\", 1]\n",
      "[\"Conscience\", 1]\n",
      "[\"Mender\", 1]\n",
      "[\"bad\", 1]\n",
      "[\"soules\", 1]\n",
      "[\"Fla\", 1]\n",
      "[\"Leaves\", 1]\n",
      "[\"Grass\", 1]\n",
      "[\"Walt\", 2]\n",
      "[\"Whitman\", 2]\n",
      "[\"1855\", 1]\n",
      "[\"Come\", 1]\n",
      "[\"Such\", 1]\n",
      "[\"verses\", 2]\n",
      "[\"Body\", 2]\n",
      "[\"let\", 1]\n",
      "[\",)\", 2]\n",
      "[\"should\", 1]\n",
      "[\"after\", 1]\n",
      "[\"return\", 1]\n",
      "[\"Or\", 1]\n",
      "[\"hence\", 1]\n",
      "[\"other\", 1]\n",
      "[\"spheres\", 1]\n",
      "[\"There\", 1]\n",
      "[\"group\", 1]\n",
      "[\"mates\", 1]\n",
      "[\"chants\", 1]\n",
      "[\"resuming\", 1]\n",
      "[\"Tallying\", 1]\n",
      "[\"Earth\", 1]\n",
      "[\"soil\", 1]\n",
      "[\"trees\", 1]\n",
      "[\"winds\", 1]\n",
      "[\"tumultuous\", 1]\n",
      "[\"waves\", 1]\n",
      "[\"Ever\", 2]\n",
      "[\"pleas\", 1]\n",
      "[\"smile\", 1]\n",
      "[\"keep\", 1]\n",
      "[\"ever\", 2]\n",
      "[\"owning\", 1]\n",
      "[\"here\", 1]\n",
      "[\"now\", 2]\n",
      "[\"Signing\", 1]\n",
      "[\"Soul\", 1]\n",
      "[\"set\", 1]\n",
      "[\"them\", 1]\n",
      "[\"name\", 1]\n",
      "[\"INSCRIPTIONS\", 1]\n",
      "[\"}\", 1]\n",
      "[\"One\", 2]\n",
      "[\"Self\", 1]\n",
      "[\"self\", 1]\n",
      "[\"sing\", 1]\n",
      "[\"simple\", 1]\n",
      "[\"separate\", 1]\n",
      "[\"person\", 1]\n",
      "[\"Yet\", 1]\n",
      "[\"utter\", 1]\n",
      "[\"word\", 2]\n",
      "[\"Democratic\", 1]\n",
      "[\"En\", 1]\n",
      "[\"Masse\", 1]\n",
      "[\"Moby\", 1]\n",
      "[\"Dick\", 1]\n",
      "[\"Herman\", 1]\n",
      "[\"Melville\", 1]\n",
      "[\"1851\", 1]\n",
      "[\"ETYMOLOGY\", 1]\n",
      "[\"Supplied\", 1]\n",
      "[\"Late\", 1]\n",
      "[\"Consumptive\", 1]\n",
      "[\"Usher\", 2]\n",
      "[\"Grammar\", 1]\n",
      "[\"School\", 1]\n",
      "[\"pale\", 1]\n",
      "[\"threadbare\", 1]\n",
      "[\"coat\", 1]\n",
      "[\"heart\", 1]\n",
      "[\"body\", 1]\n",
      "[\"brain\", 1]\n",
      "[\"see\", 1]\n",
      "[\"him\", 2]\n",
      "[\"He\", 2]\n",
      "[\"dusting\", 1]\n",
      "[\"lexicons\", 1]\n",
      "[\"grammars\", 2]\n",
      "[\"queer\", 1]\n",
      "[\"handkerchief\", 1]\n",
      "[\"mockingly\", 1]\n",
      "[\"embellished\", 1]\n",
      "[\"flags\", 1]\n",
      "[\"known\", 1]\n",
      "[\"nations\", 1]\n",
      "[\"loved\", 1]\n",
      "[\"dust\", 1]\n",
      "[\"somehow\", 1]\n",
      "[\"mildly\", 1]\n",
      "[\"reminded\", 1]\n",
      "[\"mortality\", 1]\n"
     ]
    }
   ],
   "source": [
    "import MapReduce\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "Word Count Example in the Simple Python MapReduce Framework\n",
    "\"\"\"\n",
    "# Part 1\n",
    "mr = MapReduce.MapReduce()\n",
    "\n",
    "# Part 2\n",
    "def mapper(record):\n",
    "    # key: document identifier\n",
    "    # value: document contents\n",
    "    key = record[0]\n",
    "    value = record[1]\n",
    "    words = value.split()\n",
    "    for w in words:\n",
    "      mr.emit_intermediate(w, 1)\n",
    "\n",
    "# Part 3\n",
    "def reducer(key, list_of_values):\n",
    "    # key: word\n",
    "    # value: list of occurrence counts\n",
    "    total = 0\n",
    "    for v in list_of_values:\n",
    "      total += v\n",
    "    mr.emit((key, total))\n",
    "\n",
    "# Part 4\n",
    "inputdata = open('data/books.json')\n",
    "mr.execute(inputdata, mapper, reducer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now discuss what different parts of this program do (look at the comments in the code).\n",
    "\n",
    "In Part 1, we create a MapReduce object that is used to pass data between the map function and the reduce function.\n",
    "\n",
    "In Part 2, the mapper function tokenizes each document and emits a key-value pair. The key is a word formatted as a string and the value is the integer 1 to indicate an occurrence of word.\n",
    "\n",
    "In Part 3, the reducer function sums up the list of occurrence counts and emits a count for word. Since the mapper function emits the integer 1 for each word, each element in the list_of_values is the integer 1. The list of occurrence counts is summed and a (word, total) tuple is emitted where word is a string and total is an integer.\n",
    "\n",
    "In Part 4, the code loads the json file and executes the MapReduce query which prints the result to stdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment and Submission Details\n",
    "\n",
    "In this assignment you will need to come up with a MapReduce implementation for several problems (listed below). For each problem, we provide you with a Python script that contains code similar to the above. For each of these scripts you will need to fill in the implmentation of the map function and the reduce function. Your python submission scripts are required to have a mapper function that accepts at least 1 argument and a reducer function that accepts at least 2 arguments. Your submission is also required to have a global variable named mr which points to a MapReduce object. **YOU SHOULD NOT EDIT ANYTHING ELSE IN THE PROGRAM. IF YOU EDIT ANY OTHER PARTS OF ANY OF THE PROVIDED SCRIPTS YOU WILL RECEIVE ZERO POINTS FOR THE CORRESPONDING PROBLEMS.**\n",
    "\n",
    "In summary, you need to submit the following 5 files:\n",
    "\n",
    "`inverted_index.py\n",
    "join.py\n",
    "friend_count.py\n",
    "assymmentric_friendships.py\n",
    "multiply.py`\n",
    "\n",
    "When testing, make sure MapReduce.py is in the same directory as the solution script. We also provide you with solution data for each problem in the solutions folder. You can use those to evaluate the correctness of your scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 [20 points]\n",
    "Create an Inverted index. Given a set of documents, an inverted index is a dictionary where each word is associated with a list of the document identifiers in which that word appears.\n",
    "\n",
    "## Mapper Input\n",
    "\n",
    "The input is a 2 element list: `[document_id, text]`, where `document_id` is a string representing a document identifier and text is a string representing the text of the document. The document text may have words in upper or lower case and may contain punctuation. You should treat each token as if it was a valid word; that is, you can just use `value.split()` to tokenize the string.\n",
    "\n",
    "## Reducer Output\n",
    "\n",
    "The output should be a `(word, document ID list)` tuple where word is a String and document ID list is a list of Strings.\n",
    "\n",
    "You can test your solution to this problem using `books.json`:\n",
    "\n",
    "        python3 inverted_index.py books.json\n",
    "\n",
    "You can verify your solution against `inverted_index.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 [20 points]\n",
    "Implement a relational join as a MapReduce query\n",
    "\n",
    "Consider the following query:\n",
    "\n",
    "`SELECT * \n",
    "FROM Orders, LineItem \n",
    "WHERE Order.order_id = LineItem.order_id`\n",
    "Your MapReduce query should produce the same result as this SQL query executed against an appropriate database.\n",
    "\n",
    "You can consider the two input tables, Order and LineItem, as one big concatenated bag of records that will be processed by the map function record by record.\n",
    "\n",
    "## Map Input\n",
    "\n",
    "Each input record is a list of strings representing a tuple in the database. Each list element corresponds to a different attribute of the table\n",
    "\n",
    "The first item (index 0) in each record is a string that identifies the table the record originates from. This field has two possible values:\n",
    "\n",
    "\"line_item\" indicates that the record is a line item.\n",
    "\"order\" indicates that the record is an order.\n",
    "The second element (index 1) in each record is the order_id.\n",
    "\n",
    "LineItem records have 17 attributes including the identifier string.\n",
    "\n",
    "Order records have 10 elements including the identifier string.\n",
    "\n",
    "## Reduce Output\n",
    "\n",
    "The output should be a joined record: a single list of length 27 that contains the attributes from the order record followed by the fields from the line item record. Each list element should be a string.\n",
    "\n",
    "You can test your solution to this problem using `records.json`:\n",
    "\n",
    "        python3 join.py records.json\n",
    "\n",
    "You can verify your solution against `join.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 [20 points]\n",
    "\n",
    "Consider a simple social network dataset consisting of a set of key-value pairs `(person, friend)` representing a friend relationship between two people. Write a MapReduce algorithm to count the number of friends for each person.\n",
    "\n",
    "## Map Input\n",
    "\n",
    "Each input record is a 2 element list `[personA, personB]` where `personA` is a string representing the name of a person and `personB` is a string representing the name of one of `personA`'s friends. Note that it may or may not be the case that the `personA` is a friend of `personB`.\n",
    "\n",
    "## Reduce Output\n",
    "\n",
    "The output should be a pair `(person, friend_count)` where person is a string and `friend_count` is an integer indicating the number of friends associated with person.\n",
    "\n",
    "You can test your solution to this problem using `friends.json`:\n",
    "\n",
    "        python3 friend_count.py friends.json\n",
    "\n",
    "You can verify your solution against `friend_count.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4 [20 points]\n",
    "\n",
    "The relationship `friend` is often symmetric, meaning that if I am your friend, you are my friend. Implement a MapReduce algorithm to check whether this property holds. Generate a list of all non-symmetric friend relationships.\n",
    "\n",
    "## Map Input\n",
    "\n",
    "Each input record is a 2 element list `[personA, personB]` where `personA` is a string representing the name of a person and `personB` is a string representing the name of one of `personA`'s friends. Note that it may or may not be the case that the `personA` is a friend of `personB`.\n",
    "\n",
    "## Reduce Output\n",
    "\n",
    "The output should be all pairs `(friend, person)` such that `(person, friend)` appears in the dataset but `(friend, person)` does not.\n",
    "\n",
    "You can test your solution to this problem using `friends.json`:\n",
    "\n",
    "        python3 assymmentric_friendships.py friends.json\n",
    "\n",
    "You can verify your solution against `assymetric_friendships.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5 [20 points]\n",
    "\n",
    "Assume you have two 5 x 5 matrices `A` and `B` in a sparse matrix format, where each record is of the form i, j, value. Design a MapReduce algorithm to compute the matrix multiplication `A x B`. \n",
    "\n",
    "## Map Input\n",
    "\n",
    "The input to the map function will be a row of a matrix represented as a list. Each list will be of the form `[matrix, i, j, value]` where matrix is a string and i, j, and value are integers.\n",
    "\n",
    "The first item, matrix, is a string that identifies which matrix the record originates from. This field has two possible values: \"a\" indicates that the record is from matrix A and \"b\" indicates that the record is from matrix B\n",
    "\n",
    "## Reduce Output\n",
    "\n",
    "The output from the reduce function will also be a row of the result matrix represented as a tuple. Each tuple will be of the form `(i, j, value)` where each element is an integer.\n",
    "\n",
    "You can test your solution to this problem using `matrix.json`:\n",
    "\n",
    "        python3 multiply.py matrix.json\n",
    "\n",
    "You can verify your solution against `multiply.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
